{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbccedd6",
   "metadata": {},
   "source": [
    "# Comparing classifiers for multi-class classifications of handwritten digits\n",
    "\n",
    "### KNN, logistic regression, SVM, kernel SVM, and neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ad713",
   "metadata": {},
   "source": [
    "### complete dataset is available here: http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8222d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io as spio\n",
    "import scipy.io as sio\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "data_path = \"./data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5929497",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b635da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\stuti\\\\Desktop\\\\ISYE 6740_Summer2023\\\\HW 4\\\\homework4\\\\data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd=os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "002fd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat(\"mnist_10digits.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f53e10c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#standardizing features \n",
    "\n",
    "X_train = data[\"xtrain\"]/255\n",
    "y_train= data[\"ytrain\"].ravel()\n",
    "X_test = data[\"xtest\"]/255\n",
    "y_test = data[\"ytest\"].ravel()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb7979ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      5923\n",
      "           1       0.90      0.99      0.94      6742\n",
      "           2       0.96      0.90      0.93      5958\n",
      "           3       0.91      0.93      0.92      6131\n",
      "           4       0.95      0.91      0.93      5842\n",
      "           5       0.92      0.91      0.92      5421\n",
      "           6       0.96      0.97      0.97      5918\n",
      "           7       0.93      0.94      0.93      6265\n",
      "           8       0.97      0.85      0.90      5851\n",
      "           9       0.88      0.92      0.90      5949\n",
      "\n",
      "    accuracy                           0.93     60000\n",
      "   macro avg       0.93      0.93      0.93     60000\n",
      "weighted avg       0.93      0.93      0.93     60000\n",
      "\n",
      "[[5830    3   14    4    2   26   33    4    4    3]\n",
      " [   0 6696   12    8    8    0    4    8    3    3]\n",
      " [  97  183 5390   39    7   11   24  148   42   17]\n",
      " [  22   57   67 5694    2  119    6   48   61   55]\n",
      " [  20  104    8    1 5313    1   26   23    2  344]\n",
      " [  51   53   12  198   27 4926   86    5   20   43]\n",
      " [  64   43    3    2    8   39 5757    0    1    1]\n",
      " [   7  139   26   10   50    4    0 5863    1  165]\n",
      " [  47  147   47  229   55  187   36   41 4947  115]\n",
      " [  30   31   12   60  150   19    4  137    7 5499]]\n"
     ]
    }
   ],
   "source": [
    "#fit KNN using reduced datasets \n",
    "\n",
    "model = KNeighborsClassifier(3)\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "print(model)\n",
    "\n",
    "#testing dataset\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61f7e3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.93      0.90      0.91      1032\n",
      "           3       0.90      0.92      0.91      1010\n",
      "           4       0.94      0.94      0.94       982\n",
      "           5       0.90      0.87      0.88       892\n",
      "           6       0.94      0.95      0.95       958\n",
      "           7       0.93      0.92      0.93      1028\n",
      "           8       0.88      0.88      0.88       974\n",
      "           9       0.91      0.92      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "[[ 955    0    2    4    1   10    4    3    1    0]\n",
      " [   0 1110    5    2    0    2    3    2   11    0]\n",
      " [   6    9  930   14   10    3   12   10   34    4]\n",
      " [   4    1   16  925    1   23    2   10   19    9]\n",
      " [   1    3    7    3  921    0    6    5    6   30]\n",
      " [   9    2    3   35   10  777   15    6   31    4]\n",
      " [   8    3    8    2    6   16  912    2    1    0]\n",
      " [   1    7   23    7    6    1    0  947    4   32]\n",
      " [   9   11    6   22    7   29   13   10  855   12]\n",
      " [   9    8    1    9   21    7    0   21    9  924]]\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "model_LR = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model_LR.fit(X_train, y_train)\n",
    "print(model_LR)\n",
    "\n",
    "\n",
    "#testing data\n",
    "# make predictions\n",
    "expected_LR_test = y_test\n",
    "predicted_LR_test = model_LR.predict(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected_LR_test, predicted_LR_test))\n",
    "print(metrics.confusion_matrix(expected_LR_test, predicted_LR_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f7e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.94      0.95      0.94      1032\n",
      "           3       0.93      0.95      0.94      1010\n",
      "           4       0.95      0.95      0.95       982\n",
      "           5       0.95      0.93      0.94       892\n",
      "           6       0.96      0.97      0.96       958\n",
      "           7       0.96      0.93      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[[ 965    0    2    0    0    6    5    1    1    0]\n",
      " [   0 1123    2    2    1    2    2    0    2    1]\n",
      " [   7    1  979   10    3    0    8   10   13    1]\n",
      " [   0    0   17  960    1   11    1    8    6    6]\n",
      " [   2    1    6    0  931    0   10    3    2   27]\n",
      " [   3    1    2   26    3  834   13    1    8    1]\n",
      " [   5    3    4    0    5    8  931    0    2    0]\n",
      " [   2   15   21    1    6    0    0  961    2   20]\n",
      " [   5    0   11   13    6   15    3    5  911    5]\n",
      " [   6    5    2   16   20    3    1    7    5  944]]\n"
     ]
    }
   ],
   "source": [
    "# fit a SVM model to the data\n",
    "model_svm = SVC(kernel='rbf')\n",
    "model_svm.fit(X_train_sm, y_train_sm)\n",
    "print(model_svm)\n",
    "\n",
    "\n",
    "#testing data\n",
    "\n",
    "# make predictions\n",
    "expected_svm_test = y_test\n",
    "predicted_svm_test = model_svm.predict(X_test)\n",
    "\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected_svm_test, predicted_svm_test))\n",
    "print(metrics.confusion_matrix(expected_svm_test, predicted_svm_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ada36c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.95      0.99      0.97      1135\n",
      "           2       0.92      0.90      0.91      1032\n",
      "           3       0.90      0.91      0.91      1010\n",
      "           4       0.91      0.93      0.92       982\n",
      "           5       0.89      0.88      0.88       892\n",
      "           6       0.92      0.95      0.94       958\n",
      "           7       0.93      0.91      0.92      1028\n",
      "           8       0.92      0.87      0.89       974\n",
      "           9       0.91      0.90      0.90      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "[[ 959    0    1    1    2    6    8    1    2    0]\n",
      " [   0 1121    2    2    0    1    3    1    5    0]\n",
      " [  13    2  925   14   10    2   23   12   27    4]\n",
      " [   4    2   23  918    1   27    2   14   15    4]\n",
      " [   1    1    7    0  910    1   12    3    2   45]\n",
      " [   9    9    3   44    9  782   19    3    9    5]\n",
      " [  12    4    9    1    7   16  908    0    1    0]\n",
      " [   3   22   24    2    9    0    0  938    5   25]\n",
      " [   7    7   11   23   12   38    7   10  848   11]\n",
      " [  10    7    3   12   35    4    1   22    8  907]]\n"
     ]
    }
   ],
   "source": [
    "#kernel SVM\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear', C = 0.01)\n",
    "clf_svm.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "#testing data\n",
    "\n",
    "# make predictions\n",
    "expected_clf_svm_test = y_test\n",
    "predicted_clf_svm_test = clf_svm.predict(X_test)\n",
    "\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected_clf_svm_test, predicted_clf_svm_test))\n",
    "print(metrics.confusion_matrix(expected_clf_svm_test, predicted_clf_svm_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daedfacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=1, hidden_layer_sizes=(20, 10), max_iter=1000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.96      0.96      0.96      1010\n",
      "           4       0.94      0.96      0.95       982\n",
      "           5       0.94      0.96      0.95       892\n",
      "           6       0.95      0.95      0.95       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.96      0.94      0.95       974\n",
      "           9       0.96      0.93      0.94      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "[[ 966    0    0    0    0    4    5    1    4    0]\n",
      " [   0 1122    2    3    0    1    2    2    3    0]\n",
      " [   9    3  978   10   11    0    6   10    5    0]\n",
      " [   0    1    9  966    1   15    0    9    9    0]\n",
      " [   1    0    2    0  946    0   10    2    2   19]\n",
      " [   3    2    0    7    3  856    9    3    5    4]\n",
      " [   6    3    4    0   11   18  912    0    4    0]\n",
      " [   1   15   16    1    5    1    0  976    0   13]\n",
      " [   7    3    1    7    6   11   10    6  919    4]\n",
      " [   7    7    0    9   26    7    1   10    4  938]]\n"
     ]
    }
   ],
   "source": [
    "#neural networks\n",
    "\n",
    "# fit a simple neuranl network model to the data\n",
    "model_nn = MLPClassifier(alpha=1, max_iter=1000, \n",
    "                       hidden_layer_sizes=(20, 10))\n",
    "\n",
    "#model_nn = MLPClassifier(solver='sgd', learning_rate_init = 0.001, max_iter=1000, \n",
    "                       #hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    \n",
    "model_nn.fit(X_train, y_train)\n",
    "print(model_nn)\n",
    "\n",
    "# make predictions\n",
    "expected_nntest = y_test\n",
    "predicted_nntest = model_nn.predict(X_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected_nntest, predicted_nntest))\n",
    "print(metrics.confusion_matrix(expected_nntest, predicted_nntest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879c84e",
   "metadata": {},
   "source": [
    "# Performance of the classifier\n",
    "\n",
    "### Based on the testing accuracy rates of all models >90%, all classifiers are performing extremely well. Among all, SVM and Neural Network seem to be performing the best. The reason for it could be that the MNIST dataset is less linearly separable. SVM and Neural Network are also known to be good fit for multiclass predictions which was the case for this dataset as we were predicting 10 digits.\n",
    "### One should note that with further tuning, e.g. more hidden layers, the neural network approach has even more room to improve, which likely goes some ways to explaining why deep learning approaches have shown so much success for image classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
